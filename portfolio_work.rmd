---
output:
  html_document:
    df_print: paged
    toc: true
    toc_depth: 2
---


```{r setup}
library(tidyverse); library(lubridate); library(ggalluvial); library(ggthemes); library(moments); library(ggcorrplot); library(scales); library(knitr); library(ggalt)

opts_chunk$set(message = FALSE, warning = FALSE)
```


# Introduction

To demonstrate use of business intelligence tools, complete a fictitious business case using tables, graphs, dashboards, or programs, as applicable

# Prompt

JetBlue Airways Corporation is a New York-based air carrier which received revenue of $7.7 billion in 2018. However, in recent years, JetBlue has seen its operating income decrease as its operating expenses have increased.

Determine whether JetBlue's competitors have experienced similar effects using the excerpts of income statements below.

The COO suspects the increased expenses are related to compensation passengers may receive when a flight is delayed. To start, she wishes to better understand delays at the carrier's New York hub.

```{r echo=FALSE, message=FALSE, warning=FALSE, paged.print=FALSE}
air_fin_raw <- read_csv('air_fin_raw.csv')
air_fin_raw
```

# Analysis

## Comparing JetBlue operations cost growth to competitors

Combine the income statements, gather the dates, and add calculated columns for operations cost and operations income growth. In the column labeled, "expense_growth," JetBlue's growth is as large or greater than that of all of its competitors across every year.


```{r}
# Loading 

air_fin_raw %>%
  gather(-(1:2), key = "date", value = "amt_1000usd") %>%
  spread(key = 2, value = 4) %>%
  select(1:2, operations_expenses = 4) %>%
  mutate(date = year(mdy(date)),
         expense_growth = round(if_else(company == lag(company), (operations_expenses - lag(operations_expenses)) / lag(operations_expenses), NULL), 2)) %>%
  filter(!is.na(expense_growth))


```

This can be shown even more clearly in a graph

```{r}
air_fin_raw %>%
  gather(-(1:2), key = "date", value = "amt_1000usd") %>%
  spread(key = 2, value = 4) %>%
  select(1:2, opn_exp = 4, opn_inc = 3) %>%
  mutate(date = mdy(date),
         exp_growth = if_else(company == lag(company), (opn_exp - lag(opn_exp)) / lag(opn_exp), NULL)) %>%
  filter(!is.na(exp_growth)) %>%
  ggplot() +
  geom_col(mapping = aes(x = year(date), y = exp_growth, fill = date, alpha = (company == 'JBLU')), color = "black") +
  facet_wrap(facets = ~company, nrow = 1) +
  theme_excel_new() +
  theme(legend.position = "none") +
  labs(title = 'Each airline has experienced cost growth but none more than JetBlue',
       caption = 'Annual operations expense growth per year in percent') +
  scale_y_continuous(labels = percent_format(accuracy = 1)) +
  scale_alpha_discrete(range = c(0.4, 1))
```

We may thus conclude that JetBlue's operational expenses are outpacing its competitors.

## Explore JetBlue's flight delays

The COO also asked us to explore flight delays among JetBlue and its competitors

```{r message=FALSE, warning=FALSE, include=FALSE}
# Load and store raw data set

# flights_17 %>%
#   group_by(carrier) %>%
#   summarize(num_flights = n()) %>%
#   arrange(desc(num_flights))
# 
# flights_wide <- flights %>%
#   select(-(1:3),-hour) %>%
#   left_join(weather, by = c("time_hour", "origin")) %>%
#   select(-(year:hour)) %>%
#   left_join(planes, by = 'tailnum') %>%
#   left_join(airports, by = c('dest' = 'faa')) %>%
#   filter(!is.na(seats) &
#            !is.na(dep_delay)) %>%
#   mutate(price = seats * 200,
#          cost = 15 * distance + (dep_delay > 0) * seats * dep_delay)

    # col_logical() [l], containing only T, F, TRUE or FALSE.
    # col_integer() [i], integers.
    # col_double() [d], doubles.
    # col_character() [c], everything else.
    # col_factor(levels, ordered) [f], a fixed set of values.
    # col_date(format = "") [D]: with the locale's date_format.
    # col_time(format = "") [t]: with the locale's time_format.
    # col_datetime(format = "") [T]: ISO8601 date times
    # col_number() [n], numbers containing the grouping_mark
    # col_skip() [_, -], don't import this column.
    # col_guess() [?], parse using the "best" type based on the input.
# iiiii icicc
# ciiiT dddid
# ddddi cccii
# dccdd iicci i

fly_wide <- read_csv(file = 'flights_wide.csv', trim_ws = T, col_types = 'iiiiiiciccciiiTdddidddddiccciidccddiiccii')

  
```



```{r message=FALSE, warning=FALSE}
# Copy to a test set and mutate it into something testable
test_17 <- fly_wide %>%
  filter(!is.na(dep_delay)) %>% ## Remove flights that are missing dep_delay
  mutate(month = month(time_hour),
         day = day(time_hour)) %>%
  group_by(month) %>%
  mutate(on_time = dep_delay <= 1, ## This and the next line split the data set into on-time flights...
         ln_delay = if_else(dep_delay > 1, log(dep_delay), NA_real_), ## ...and log-length of delay, if delay
         wkday = weekdays(time_hour)) %>%
  ungroup()


```


```{r eval=FALSE, message=FALSE, warning=FALSE, include=FALSE}
# test correlations for time of year
corr_list <- tibble(x = 50, ontime_cor = 0.00, lndelay_cor = 0.00)

for(i in 50:300) {
  corr_list[[i, 1]] <- i
  corr_list[[i, 2]] <- round(cor(abs(yday(test_17$time_hour) - i), test_17$on_time, use = 'pairwise.complete.obs'), 4)
  corr_list[[i, 3]] <- round(cor(abs(yday(test_17$time_hour) - i), test_17$ln_delay, use = 'pairwise.complete.obs'), 4)
}

corr_list %>%
  mutate(avg = abs(ontime_cor * lndelay_cor)) %>%
  arrange(desc(abs(ontime_cor))) %>%
  head()

## On-time correlation peaks at day 121
## ln delay correlation peaks at day 168
  
```


```{r eval=FALSE, message=FALSE, warning=FALSE, include=FALSE}
# test correlations for time of day


corr_list <- tibble(x = 100, ontime_cor = 0.00, lndelay_cor = 0.00)

for(i in 1:23) {
  for(j in 0:59) {
    
  corr_list[[i * 100 + j, 1]] <- i*100 + j
  corr_list[[i * 100 + j, 2]] <- round(
    cor(
      abs(interval
          (start = ymd_hm(
            paste(
              2017,
              month(test_17$time_hour),
              day(test_17$time_hour),
              i,
              j)),
            end = ymd_hm(
              paste(
                2017,
                month(test_17$time_hour),
                day(test_17$time_hour),
                hour(test_17$time_hour),
              test_17$minute))) /
            dminutes(1)),
    test_17$on_time,
    use = 'pairwise.complete.obs'), 4)

  
    
  corr_list[[i * 100 + j, 3]] <- round(
    cor(
      abs(
        interval(
          start = ymd_hm(paste(2017,
                               month(test_17$time_hour),
                               day(test_17$time_hour),
                               i,
                               j)),
          end = ymd_hm(paste(2017,
                             month(test_17$time_hour),
                             day(test_17$time_hour),
                             hour(test_17$time_hour),
                             test_17$minute))) /
          dminutes(1)),
    test_17$ln_delay,
    use = 'pairwise.complete.obs'), 4)
  
  }
}

corr_list %>%
  arrange(desc(abs(lndelay_cor))) %>%
  head()

## On-time correlation peaks at time 20:19
## ln delay correlation peaks at time 20:29
  
```



```{r}
# Add transformed time and date data to the test set
testb_17 <- test_17 %>%
  mutate(diff_121day = abs(yday(time_hour) - 121),
         diff_168day = abs(yday(time_hour) - 168),
         diff_2019min = interval(start = ymd_hm(paste(2017,
                      month(time_hour),
                      day(time_hour),
                      20,
                      19)),
         end = ymd_hm(paste(2017,
                      month(time_hour),
                      day(time_hour),
                      hour(time_hour),
                      minute))) / dminutes(1),
         diff_2029min = interval(start = ymd_hm(paste(2017,
                      month(time_hour),
                      day(time_hour),
                      20,
                      29)),
         end = ymd_hm(paste(2017,
                      month(time_hour),
                      day(time_hour),
                      hour(time_hour),
                      minute))) / dminutes(1))




  


```

Before continuing, I want to explain and justify why I used this method rather than using unchanged time or date.

The biggest change in time would be between 00:00 and 23:59. The biggest schange in date would be between 1 January and 31 December. 

```{r, message=FALSE}
testb_17 %>%
  mutate(hour = hour(time_hour)) %>%
  group_by(hour, minute) %>%
  summarize(mean_ontime = mean(on_time, na.rm = T),
            mean_lndelay = mean(ln_delay, na.rm = T)) %>%
  ggplot(mapping = aes(x = hour + minute/60, y = mean_ontime)) +
  geom_point() +
  geom_smooth()

testb_17 %>%
  mutate(hour = hour(time_hour)) %>%
  group_by(hour, minute) %>%
  summarize(mean_ontime = mean(on_time, na.rm = T),
            mean_lndelay = mean(ln_delay, na.rm = T)) %>%
  ggplot(mapping = aes(x = hour + minute/60, y = mean_lndelay)) +
  geom_point() +
  geom_smooth()



## With this plot, I wanted to show why I chose to use a difference factor
## rather than just using the time of day variable. Intuitively, the
## reason is that the change from 23:59 to 00:00 is the biggest numerically
## but doesn't mean much in practice

# pred_17 %>%
#   select(diff_21h, time_metric, pred_delay) %>%
#   unique() %>%
#   ggplot() +
#   geom_point(mapping = aes(time_metric, p_on_time, color = 'time'), size = 1) +
#   geom_smooth(aes(time_metric, p_on_time, color = 'time'), method = 'loess') +
#   geom_point(mapping = aes(diff_21h, p_on_time, color = 'adj_time'), size = 1) +
#   geom_smooth(aes(diff_21h, p_on_time, color = 'adj_time'), method = 'loess') +
#   theme_bw()
```


```{r}
## Build a correlogram
testb_17 %>%
  filter(carrier == 'B6') %>%
  select(on_time:ln_delay,
         air_time:distance,
         temp:year,
         engines:speed,
         diff_121day:diff_2029min) %>%
  cor(use = "pairwise.complete.obs") %>%
  round(1) %>%
  ggcorrplot(lab = TRUE,
             #method="circle",
             type = "lower",
             lab_size = 3,
             colors = c("orange", "white", "dodgerblue"), 
             title="Correlogram of flight and weather data",
             legend = 'Correlation',
             ggtheme = theme_bw())
  
    
    



```


```{r}

testb_17 %>%
  filter(!is.na(temp) & !is.na(dewp)) %>%
  ggplot(mapping = aes(x = temp, y = dewp, na.rm = T)) +
  geom_point() +
  geom_smooth(method = 'lm', color = 'darkgray', fill = 'darkgray', alpha = 0.8, linetype = 'dashed') +
  geom_count(color = 'dodgerblue', show.legend = F, na.rm = T) +
  theme_bw() +
  labs(title = "The correlation between temperature and dewpoint makes using both redundant",
       x = "temperature in degrees",
       y = "dewpoint in degrees")


  
```



```{r}
testb_17 %>%
  mutate(is_b6 = (carrier == 'B6'),
         yrmo = 12 / 365 * yday(time_hour)) %>%
  group_by(yrmo, is_b6) %>%
  summarize(mean_on_time = mean(on_time)) %>%
  group_by(yrmo) %>%
  mutate(b6_v_others = if_else(is_b6 == T,
                                 mean_on_time - mean(mean_on_time),
                                 mean(mean_on_time) - mean_on_time)) %>%
  summarize(b6_factor = sum(b6_v_others)) %>%
  ggplot(mapping = aes(x = yrmo, ymax = b6_factor, ymin = 0)) +
  geom_ribbon(fill = 'dodgerblue') +
  geom_smooth()
  scale_x_continuous(labels = month.abb[1:12], breaks = 1:12) +
  theme_bw() +
  labs(title = 'JetBlue lags in on-time departures all year but especially in summer months',
       x = 'date',
       y = 'Percent diff. in JetBlue on-time departures vs. competitors')

  
  
```

```{r message=FALSE, warning=FALSE}

testb_17 %>%
  filter(carrier %in% c('AA', 'B6', 'DL', 'UA') &
           !is.na(ln_delay)) %>%
  group_by(carrier) %>%
  summarize(q1 = quantile(dep_delay, 0.25),
            q3 = quantile(dep_delay, 0.75)) %>%
  ggplot(mapping = aes(x = q1, xend = q3, y = carrier)) +
  geom_dumbbell(color_x = "dodgerblue",
                size = 2,
                size_x = 4,
                size_xend = 4,
                colour_xend = "darkblue",
                colour = 'dodgerblue') +
  labs(x = NULL,
       y = NULL,
       title = "Departure delay interquartile range is longest for JetBlue on both ends") +
  scale_x_continuous(label = minutes) +
  theme_excel_new() +
  theme(plot.title = element_text(face = "bold"),
              panel.grid.major.x=element_line(),
              axis.ticks=element_blank(),
              panel.border=element_blank())
  
```



```{r}
testb_17 %>%
    filter(yday(time_hour) > 152 & 
           yday(time_hour) < 244) %>%
  mutate(is_b6 = (carrier == "B6")) %>%
  ggplot(mapping = aes(x = ln_delay)) +
  geom_density(aes(fill = is_b6), alpha=0.7, na.rm = T) +
  labs(title = "JetBlue summer flights also have longer delays than competitors",
       x = "natural log of delay",
       fill="Carrier") +
  scale_fill_manual(values = c('black', 'dodgerblue'),
                    aesthetics = 'fill',
                    labels = c('Competitors', 'JetBlue'),
                    guide = guide_legend(reverse = T))


```

To build a predictive model, we'll need two estimated 

```{r}
## Build Linear model using month, time, and weekday data
mdl <- lm(data = testb_17, formula = ln_delay ~ diff_2029min + diff_168day + wkday) %>%
  summary()
mdl
```



```{r}
## Pull out the coefficients and standard error
coefs <- mdl$coefficients %>%
  as_tibble() %>%
  mutate(x_var = row.names(mdl$coefficients)) %>%
  select(5, coef = 1, se = 2)
coefs
```


```{r}
## This builds the pred_delay equation
paste(coefs[1, 2], "+",
      coefs[2, 2], "* diff_2029min +",
      coefs[3, 2], "* diff_168day +",
      coefs[4, 2], "* (wkday == 'Monday') +",
      coefs[5, 2], "* (wkday == 'Saturday') +",
      coefs[6, 2], "* (wkday == 'Sunday') +",
      coefs[7, 2], "* (wkday == 'Thursday') +",
      coefs[8, 2], "* (wkday == 'Tuesday') +",
      coefs[9, 2], "* (wkday == 'Wednesday')")

```

```{r}
## Build logit model using month, time, and weekday data
mdl_2 <- glm(data = testb_17, formula = on_time ~ diff_2019min + diff_121day + wkday, family = 'binomial') %>%
  summary()

mdl_2
```


```{r}
coefs_2 <- mdl_2$coefficients %>%
  as_tibble() %>%
  mutate(x_var = row.names(mdl$coefficients)) %>%
  select(5, coef = 1, se = 2)
```



```{r}
## This builds the logit for p_on_time
paste(coefs_2[1, 2], "+",
      coefs_2[2, 2], "* diff_2019min +",
      coefs_2[3, 2], "* diff_121day +",
      coefs_2[4, 2], "* (wkday == 'Monday') +",
      coefs_2[5, 2], "* (wkday == 'Saturday') +",
      coefs_2[6, 2], "* (wkday == 'Sunday') +",
      coefs_2[7, 2], "* (wkday == 'Thursday') +",
      coefs_2[8, 2], "* (wkday == 'Tuesday') +",
      coefs_2[9, 2], "* (wkday == 'Wednesday')")
```



```{r}
## Add predicted delay and probability of no delay to test tibble
pred_17 <- test_17 %>%
  mutate(pred_delay = exp(3.85236933552203 +
           -0.0636324279034302 * diff_21h +
           -0.0541743901271069 * diff_5mo +
           -0.0618142578716507 * (wkday == 'Monday') +
           -0.125034427355075 * (wkday == 'Saturday') +
           -0.172379656023462 * (wkday == 'Sunday') +
           -0.108048760292188 * (wkday == 'Thursday') +
           -0.0454143145559025 * (wkday == 'Tuesday') +
           -0.17399920842538 * (wkday == 'Wednesday')),
         p_on_time = 1 / (1 + exp(-(-0.868973986936626 +
                                      0.132485588024036 * diff_21h +
                                      0.0938310236036926 * diff_5mo +
                                      0.152317762763714 * (wkday == 'Monday') +
                                      0.312356993431681 * (wkday == 'Saturday') +
                                      0.323550415257237 * (wkday == 'Sunday') +
                                      0.0979982073199806 * (wkday == 'Thursday') +
                                      0.265313809910303 * (wkday == 'Tuesday') +
                                      0.316247648362565 * (wkday == 'Wednesday')))))

```



```{r}
## Test month ##

cor_df <- tibble(i = 1L, cor_i = 0.001)

for(i in 101:1231) {
  cor_df[i, 1] <- i/100
  cor_df[i, 2] <- cor(abs(i/100 - test_17$month), test_17$ln_delay)
}

cor_df %>%
  arrange(desc(abs(cor_i)))

```


```{r}
## Test time ##

cor_df <- tibble(i = 1L, cor_i = 0.001)

for(i in 900:2300) {
  cor_df[i, 1] <- i/100
  cor_df[i, 2] <- cor(abs(i/100 - test_17$time_metric), test_17$ln_delay, use = 'pairwise.complete.obs')
}

cor_df %>%
  arrange(desc(abs(cor_i)))
```





```{r}
kurtosis(test_17$ln_delay, na.rm = T)
skewness(test_17$ln_delay, na.rm = T)
mean(test_17$ln_delay, na.rm = T)
median(test_17$ln_delay, na.rm = T)



ggplot(data = test_17, mapping = aes(ln_delay), fill = 'gray') +
  geom_histogram(na.rm = T, bins = 20) +
  geom_vline(xintercept = quantile(test_17$ln_delay, probs = 0.16, na.rm = T), color = 'darkorange', size = 1.5, linetype = 'dotted') +
  geom_vline(xintercept = quantile(test_17$ln_delay, probs = 0.84, na.rm = T), color = 'navyblue', size = 1.5, linetype = 'dotted') +
  geom_vline(xintercept = mean(test_17$ln_delay, na.rm = T), color = 'orange', size = 1.5, linetype = 'dashed') +
  geom_vline(xintercept = median(test_17$ln_delay, na.rm = T), color = 'dodgerblue', size = 1.5, linetype = 'dashed') +
  theme_fivethirtyeight() +
  scale_color_fivethirtyeight(labels = c('dodgerblue', 'orange')) +
  ggtitle('Distribution looks pretty normal')

kurtosis(test_17$dep_delay); skewness(test_17$dep_delay)
```




```{r}


  
```

